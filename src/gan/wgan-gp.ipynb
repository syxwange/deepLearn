{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## WGAN-GP\r\n",
    "构建一个带梯度惩罚的 Wasserstein GAN (WGAN-GP)，以解决您在此之前一直使用的 GAN 的一些稳定性问题。具体来说，您将使用一种称为 W-loss 的特殊损失函数，其中 W 代表 Wasserstein，并使用梯度惩罚来防止模式崩溃。\r\n",
    "https://github.com/tsuirak/deeplearning.ai/"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "from tqdm.auto import tqdm\r\n",
    "from torchvision import transforms\r\n",
    "from torchvision.datasets import MNIST\r\n",
    "from torchvision.utils import make_grid\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!\r\n",
    "\r\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\r\n",
    "    image_tensor = (image_tensor + 1) / 2\r\n",
    "    image_unflat = image_tensor.detach().cpu()\r\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\r\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "def make_grad_hook():\r\n",
    "    '''\r\n",
    "    Function to keep track of gradients for visualization purposes, \r\n",
    "    which fills the grads list when using model.apply(grad_hook).\r\n",
    "    '''\r\n",
    "    grads = []\r\n",
    "    def grad_hook(m):\r\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\r\n",
    "            grads.append(m.weight.grad)\r\n",
    "    return grads, grad_hook\r\n",
    "\r\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generator and Noise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Generator(nn.Module):\r\n",
    "    '''\r\n",
    "    Generator Class\r\n",
    "    Values:\r\n",
    "        z_dim: the dimension of the noise vector, a scalar\r\n",
    "        im_chan: the number of channels of the output image, a scalar\r\n",
    "              (MNIST is black-and-white, so 1 channel is your default)\r\n",
    "        hidden_dim: the inner dimension, a scalar\r\n",
    "    '''\r\n",
    "    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\r\n",
    "        super(Generator, self).__init__()\r\n",
    "        self.z_dim = z_dim\r\n",
    "        # Build the neural network\r\n",
    "        self.gen = nn.Sequential(\r\n",
    "            self.make_gen_block(z_dim, hidden_dim * 4),\r\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\r\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\r\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\r\n",
    "        )\r\n",
    "\r\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\r\n",
    "        '''\r\n",
    "        Function to return a sequence of operations corresponding to a generator block of DCGAN;\r\n",
    "        a transposed convolution, a batchnorm (except in the final layer), and an activation.\r\n",
    "        Parameters:\r\n",
    "            input_channels: how many channels the input feature representation has\r\n",
    "            output_channels: how many channels the output feature representation should have\r\n",
    "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\r\n",
    "            stride: the stride of the convolution\r\n",
    "            final_layer: a boolean, true if it is the final layer and false otherwise \r\n",
    "                      (affects activation and batchnorm)\r\n",
    "        '''\r\n",
    "        if not final_layer:\r\n",
    "            return nn.Sequential(\r\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\r\n",
    "                nn.BatchNorm2d(output_channels),\r\n",
    "                nn.ReLU(inplace=True),\r\n",
    "            )\r\n",
    "        else:\r\n",
    "            return nn.Sequential(\r\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\r\n",
    "                nn.Tanh(),\r\n",
    "            )\r\n",
    "\r\n",
    "    def forward(self, noise):\r\n",
    "        '''\r\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor,\r\n",
    "        returns generated images.\r\n",
    "        Parameters:\r\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\r\n",
    "        '''\r\n",
    "        x = noise.view(len(noise), self.z_dim, 1, 1)\r\n",
    "        return self.gen(x)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Critic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Critic(nn.Module):\r\n",
    "    '''\r\n",
    "    Critic Class\r\n",
    "    Values:\r\n",
    "        im_chan: the number of channels of the output image, a scalar\r\n",
    "              (MNIST is black-and-white, so 1 channel is your default)\r\n",
    "        hidden_dim: the inner dimension, a scalar\r\n",
    "    '''\r\n",
    "    def __init__(self, im_chan=1, hidden_dim=64):\r\n",
    "        super(Critic, self).__init__()\r\n",
    "        self.crit = nn.Sequential(\r\n",
    "            self.make_crit_block(im_chan, hidden_dim),\r\n",
    "            self.make_crit_block(hidden_dim, hidden_dim * 2),\r\n",
    "            self.make_crit_block(hidden_dim * 2, 1, final_layer=True),\r\n",
    "        )\r\n",
    "\r\n",
    "    def make_crit_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\r\n",
    "        '''\r\n",
    "        Function to return a sequence of operations corresponding to a critic block of DCGAN;\r\n",
    "        a convolution, a batchnorm (except in the final layer), and an activation (except in the final layer).\r\n",
    "        Parameters:\r\n",
    "            input_channels: how many channels the input feature representation has\r\n",
    "            output_channels: how many channels the output feature representation should have\r\n",
    "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\r\n",
    "            stride: the stride of the convolution\r\n",
    "            final_layer: a boolean, true if it is the final layer and false otherwise \r\n",
    "                      (affects activation and batchnorm)\r\n",
    "        '''\r\n",
    "        if not final_layer:\r\n",
    "            return nn.Sequential(\r\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\r\n",
    "                nn.BatchNorm2d(output_channels),\r\n",
    "                nn.LeakyReLU(0.2, inplace=True),\r\n",
    "            )\r\n",
    "        else:\r\n",
    "            return nn.Sequential(\r\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\r\n",
    "            )\r\n",
    "\r\n",
    "    def forward(self, image):\r\n",
    "        '''\r\n",
    "        Function for completing a forward pass of the critic: Given an image tensor, \r\n",
    "        returns a 1-dimension tensor representing fake/real.\r\n",
    "        Parameters:\r\n",
    "            image: a flattened image tensor with dimension (im_chan)\r\n",
    "        '''\r\n",
    "        crit_pred = self.crit(image)\r\n",
    "        return crit_pred.view(len(crit_pred), -1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Penalt\r\n",
    "计算梯度惩罚可以分为两个函数：\r\n",
    "1. 计算图像的梯度；\r\n",
    "2. 计算给定梯度的梯度惩罚。\r\n",
    "你可以从获得梯度开始。梯度是通过首先创建一个混合图像来计算的。这是通过使用epsilon对假图像和真图像进行加权，然后将它们相加来完成的。一旦你有了中间图像，你就可以在图像上得到批评家的输出。最后，计算混合图像（输出）上的批评家分数相对于混合图像（输入）像素的梯度。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\r\n",
    "# GRADED FUNCTION: get_gradient\r\n",
    "def get_gradient(crit, real, fake, epsilon):\r\n",
    "    '''\r\n",
    "    Return the gradient of the critic's scores with respect to mixes of real and fake images.\r\n",
    "    Parameters:\r\n",
    "        crit: the critic model\r\n",
    "        real: a batch of real images\r\n",
    "        fake: a batch of fake images\r\n",
    "        epsilon: a vector of the uniformly random proportions of real/fake per mixed image\r\n",
    "            每个混合图像中真实/虚假的均匀随机比例向量\r\n",
    "    Returns:\r\n",
    "        gradient: the gradient of the critic's scores, with respect to the mixed image\r\n",
    "    '''\r\n",
    "    # Mix the images together\r\n",
    "    mixed_images = real * epsilon + fake * (1 - epsilon)\r\n",
    "    # Calculate the critic's scores on the mixed images\r\n",
    "    mixed_scores = crit(mixed_images)    \r\n",
    "    # Take the gradient of the scores with respect to the images\r\n",
    "    gradient = torch.autograd.grad(\r\n",
    "        # Note: You need to take the gradient of outputs with respect to inputs.\r\n",
    "        # This documentation may be useful, but it should not be necessary:\r\n",
    "        # https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad\r\n",
    "        #### START CODE HERE ####\r\n",
    "        inputs=mixed_images,\r\n",
    "        outputs=mixed_scores,\r\n",
    "        #### END CODE HERE ####\r\n",
    "        # These other parameters have to do with the pytorch autograd engine works\r\n",
    "        grad_outputs=torch.ones_like(mixed_scores), \r\n",
    "        create_graph=True,\r\n",
    "        retain_graph=True,\r\n",
    "    )\r\n",
    "    return gradient[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The second function you need to complete is to compute the gradient penalty given the gradient. First, you calculate the magnitude of each image's gradient. The magnitude of a gradient is also called the norm. Then, you calculate the penalty by squaring the distance between each magnitude and the ideal norm of 1 and taking the mean of all the squared distances\r\n",
    "需要完成的第二个函数是计算给定梯度的梯度惩罚。首先，计算每个图像梯度的大小。梯度的大小也称为范数。然后，通过将每个震级与理想范数1之间的距离平方，并取所有平方距离的平均值来计算惩罚"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\r\n",
    "# GRADED FUNCTION: gradient_penalty\r\n",
    "def gradient_penalty(gradient):\r\n",
    "    '''\r\n",
    "    Return the gradient penalty, given a gradient.\r\n",
    "    Given a batch of image gradients, you calculate the magnitude of each image's gradient\r\n",
    "    and penalize the mean quadratic distance of each magnitude to 1.\r\n",
    "    Parameters:\r\n",
    "        gradient: the gradient of the critic's scores, with respect to the mixed image\r\n",
    "    Returns:\r\n",
    "        penalty: the gradient penalty\r\n",
    "    '''\r\n",
    "    # Flatten the gradients so that each row captures one image\r\n",
    "    gradient = gradient.view(len(gradient), -1)\r\n",
    "    # Calculate the magnitude of every row\r\n",
    "    gradient_norm = gradient.norm(2, dim=1)    \r\n",
    "    # Penalize the mean squared distance of the gradient norms from 1\r\n",
    "    #### START CODE HERE ####\r\n",
    "    penalty = torch.mean((gradient_norm - 1)**2)\r\n",
    "    #### END CODE HERE ####\r\n",
    "    return penalty"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Losses\r\n",
    "For the critic, the loss is calculated by maximizing the distance between the critic's predictions on the real images and the predictions on the fake images while also adding a gradient penalty. The gradient penalty is weighed according to lambda. The arguments are the scores for all the images in the batch, and you will use the mean of them.\r\n",
    "对于批评家，损失是通过最大化批评家对真实图像的预测和对虚假图像的预测之间的距离来计算的，同时还添加了梯度惩罚。根据lambda对梯度惩罚进行加权。参数是批处理中所有图像的分数，您将使用它们的平均值。\r\n",
    "- get_crit_loss\r\n",
    "    1. The higher the mean fake score, the higher the critic's loss is.\r\n",
    "    2. What does this suggest about the mean real score?\r\n",
    "    3. The higher the gradient penalty, the higher the critic's loss is, proportional to lambda."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\r\n",
    "# GRADED FUNCTION: get_gen_loss\r\n",
    "def get_gen_loss(crit_fake_pred):\r\n",
    "    '''\r\n",
    "    Return the loss of a generator given the critic's scores of the generator's fake images.\r\n",
    "    Parameters:\r\n",
    "        crit_fake_pred: the critic's scores of the fake images\r\n",
    "    Returns:\r\n",
    "        gen_loss: a scalar loss value for the current batch of the generator\r\n",
    "    '''\r\n",
    "    #### START CODE HERE ####\r\n",
    "    gen_loss = -1. * torch.mean(crit_fake_pred)\r\n",
    "    #### END CODE HERE ####\r\n",
    "    return gen_loss\r\n",
    "\r\n",
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\r\n",
    "# GRADED FUNCTION: get_crit_loss\r\n",
    "def get_crit_loss(crit_fake_pred, crit_real_pred, gp, c_lambda):\r\n",
    "    '''\r\n",
    "    Return the loss of a critic given the critic's scores for fake and real images,\r\n",
    "    the gradient penalty, and gradient penalty weight.\r\n",
    "    Parameters:\r\n",
    "        crit_fake_pred: the critic's scores of the fake images\r\n",
    "        crit_real_pred: the critic's scores of the real images\r\n",
    "        gp: the unweighted gradient penalty\r\n",
    "        c_lambda: the current weight of the gradient penalty \r\n",
    "    Returns:\r\n",
    "        crit_loss: a scalar for the critic's loss, accounting for the relevant factors\r\n",
    "    '''\r\n",
    "    #### START CODE HERE ####\r\n",
    "    crit_loss = torch.mean(crit_fake_pred) - torch.mean(crit_real_pred) + c_lambda * gp\r\n",
    "    #### END CODE HERE ####\r\n",
    "    return crit_loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Putting It All Together\r\n",
    "Before you put everything together, there are a few things to note.\r\n",
    "1.   Even on GPU, the **training will run more slowly** than previous labs because the gradient penalty requires you to compute the gradient of a gradient -- this means potentially a few minutes per epoch! For best results, run this for as long as you can while on GPU.\r\n",
    "2.   One important difference from earlier versions is that you will **update the critic multiple times** every time you update the generator This helps prevent the generator from overpowering the critic. Sometimes, you might see the reverse, with the generator updated more times than the critic. This depends on architectural (e.g. the depth and width of the network) and algorithmic choices (e.g. which loss you're using). \r\n",
    "3.   WGAN-GP isn't necessarily meant to improve overall performance of a GAN, but just **increases stability** and avoids mode collapse. In general, a WGAN will be able to train in a much more stable way than the vanilla DCGAN from last assignment, though it will generally run a bit slower. You should also be able to train your model for more epochs without it collapsing.\r\n",
    "\r\n",
    "###  Training Initializations\r\n",
    "Now you can start putting it all together.\r\n",
    "As usual, you will start by setting the parameters:\r\n",
    "  *   n_epochs: the number of times you iterate through the entire dataset when training\r\n",
    "  *   z_dim: the dimension of the noise vector\r\n",
    "  *   display_step: how often to display/visualize the images\r\n",
    "  *   batch_size: the number of images per forward/backward pass\r\n",
    "  *   lr: the learning rate\r\n",
    "  *   beta_1, beta_2: the momentum terms\r\n",
    "  *   c_lambda: weight of the gradient penalty\r\n",
    "  *   crit_repeats: number of times to update the critic per generator update - there are more details about this in the *Putting It All Together* section\r\n",
    "  *   device: the device type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_epochs = 100\r\n",
    "z_dim = 64\r\n",
    "display_step = 500\r\n",
    "batch_size = 128\r\n",
    "lr = 0.0002\r\n",
    "beta_1 = 0.5\r\n",
    "beta_2 = 0.999\r\n",
    "c_lambda = 10\r\n",
    "crit_repeats = 5\r\n",
    "\r\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\r\n",
    "dataloader = DataLoader(MNIST('.', download=False, transform=transform),batch_size=batch_size, shuffle=True)\r\n",
    "\r\n",
    "gen = Generator(z_dim).to(device)\r\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\r\n",
    "crit = Critic().to(device) \r\n",
    "crit_opt = torch.optim.Adam(crit.parameters(), lr=lr, betas=(beta_1, beta_2))\r\n",
    "\r\n",
    "def weights_init(m):\r\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\r\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\r\n",
    "    if isinstance(m, nn.BatchNorm2d):\r\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\r\n",
    "        torch.nn.init.constant_(m.bias, 0)\r\n",
    "gen = gen.apply(weights_init)\r\n",
    "crit = crit.apply(weights_init)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "cur_step = 0\r\n",
    "generator_losses = []\r\n",
    "critic_losses = []\r\n",
    "for epoch in range(n_epochs):\r\n",
    "    # Dataloader returns the batches\r\n",
    "    for real, _ in tqdm(dataloader):\r\n",
    "        cur_batch_size = len(real)\r\n",
    "        real = real.to(device)\r\n",
    "\r\n",
    "        mean_iteration_critic_loss = 0\r\n",
    "        for _ in range(crit_repeats):\r\n",
    "            ### Update critic ###\r\n",
    "            crit_opt.zero_grad()\r\n",
    "            fake_noise = torch.randn(cur_batch_size, z_dim, device=device)\r\n",
    "            fake = gen(fake_noise)\r\n",
    "            crit_fake_pred = crit(fake.detach())\r\n",
    "            crit_real_pred = crit(real)\r\n",
    "\r\n",
    "            epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\r\n",
    "            gradient = get_gradient(crit, real, fake.detach(), epsilon)\r\n",
    "            gp = gradient_penalty(gradient)\r\n",
    "            crit_loss = get_crit_loss(crit_fake_pred, crit_real_pred, gp, c_lambda)\r\n",
    "\r\n",
    "            # Keep track of the average critic loss in this batch\r\n",
    "            mean_iteration_critic_loss += crit_loss.item() / crit_repeats\r\n",
    "            # Update gradients\r\n",
    "            crit_loss.backward(retain_graph=True)\r\n",
    "            # Update optimizer\r\n",
    "            crit_opt.step()\r\n",
    "        critic_losses += [mean_iteration_critic_loss]\r\n",
    "\r\n",
    "        ### Update generator ###\r\n",
    "        gen_opt.zero_grad()\r\n",
    "        fake_noise_2 = torch.randn(cur_batch_size, z_dim, device=device)\r\n",
    "        fake_2 = gen(fake_noise_2)\r\n",
    "        crit_fake_pred = crit(fake_2)\r\n",
    "        \r\n",
    "        gen_loss = get_gen_loss(crit_fake_pred)\r\n",
    "        gen_loss.backward()\r\n",
    "\r\n",
    "        # Update the weights\r\n",
    "        gen_opt.step()\r\n",
    "\r\n",
    "        # Keep track of the average generator loss\r\n",
    "        generator_losses += [gen_loss.item()]\r\n",
    "\r\n",
    "        ### Visualization code ###\r\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\r\n",
    "            gen_mean = sum(generator_losses[-display_step:]) / display_step\r\n",
    "            crit_mean = sum(critic_losses[-display_step:]) / display_step\r\n",
    "            print(f\"Step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\r\n",
    "            show_tensor_images(fake)\r\n",
    "            show_tensor_images(real)\r\n",
    "            step_bins = 20\r\n",
    "            num_examples = (len(generator_losses) // step_bins) * step_bins\r\n",
    "            plt.plot(\r\n",
    "                range(num_examples // step_bins), \r\n",
    "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\r\n",
    "                label=\"Generator Loss\"\r\n",
    "            )\r\n",
    "            plt.plot(\r\n",
    "                range(num_examples // step_bins), \r\n",
    "                torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\r\n",
    "                label=\"Critic Loss\"\r\n",
    "            )\r\n",
    "            plt.legend()\r\n",
    "            plt.show()\r\n",
    "\r\n",
    "        cur_step += 1\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "81a32e34d9b6c3d3c08eec8886cc1ef58e5830ea13071be471581d66bf884ac5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}