{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## DCGAN\r\n",
    "\r\n",
    "### Learning Objectives\r\n",
    "1.   Get hands-on experience making a widely used GAN: Deep Convolutional GAN (DCGAN).\r\n",
    "2.   Train a powerful generative model.\r\n",
    "\r\n",
    "In this notebook, you're going to create another GAN using the MNIST dataset. You will implement a Deep Convolutional GAN (DCGAN), a very successful and influential GAN model developed in 2015.\r\n",
    "\r\n",
    "*   Use convolutions without any pooling layers\r\n",
    "*   Use batchnorm in both the generator and the discriminator\r\n",
    "*   Don't use fully connected hidden layers\r\n",
    "*   Use ReLU activation in the generator for all layers except for the output, which uses a Tanh activation.\r\n",
    "*   Use LeakyReLU activation in the discriminator for all layers except for the output, which does not use an activation\r\n",
    "\r\n",
    "*Note: [here](https://arxiv.org/pdf/1511.06434v1.pdf) is the paper if you are interested! It might look dense now, but soon you'll be able to understand many parts of it :)*\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "from tqdm.auto import tqdm\r\n",
    "from torchvision import transforms\r\n",
    "from torchvision.datasets import MNIST\r\n",
    "from torchvision.utils import make_grid\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!\r\n",
    "\r\n",
    "\r\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):    \r\n",
    "    image_tensor = (image_tensor + 1) / 2\r\n",
    "    image_unflat = image_tensor.detach().cpu()\r\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\r\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\r\n",
    "# GRADED FUNCTION: Generator\r\n",
    "class Generator(nn.Module):\r\n",
    "    '''\r\n",
    "    Generator Class\r\n",
    "    Values:\r\n",
    "        z_dim: the dimension of the noise vector, a scalar\r\n",
    "        im_chan: the number of channels of the output image, a scalar   (MNIST is black-and-white, so 1 channel is your default)\r\n",
    "        hidden_dim: the inner dimension, a scalar\r\n",
    "    '''\r\n",
    "    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\r\n",
    "        super(Generator, self).__init__()\r\n",
    "        self.z_dim = z_dim\r\n",
    "        # Build the neural network\r\n",
    "        self.gen = nn.Sequential(\r\n",
    "            self.make_gen_block(z_dim, hidden_dim * 4),\r\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\r\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\r\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\r\n",
    "        )\r\n",
    "\r\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\r\n",
    "        '''\r\n",
    "        Function to return a sequence of operations corresponding to a generator block of DCGAN, \r\n",
    "        corresponding to a transposed convolution, a batchnorm (except for in the last layer), and an activation.\r\n",
    "        Parameters:\r\n",
    "            input_channels: how many channels the input feature representation has\r\n",
    "            output_channels: how many channels the output feature representation should have\r\n",
    "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\r\n",
    "            stride: the stride of the convolution\r\n",
    "            final_layer: a boolean, true if it is the final layer and false otherwise \r\n",
    "                      (affects activation and batchnorm)\r\n",
    "        '''\r\n",
    "\r\n",
    "        #     Steps:\r\n",
    "        #       1) Do a transposed convolution using the given parameters.\r\n",
    "        #       2) Do a batchnorm, except for the last layer.\r\n",
    "        #       3) Follow each batchnorm with a ReLU activation.\r\n",
    "        #       4) If its the final layer, use a Tanh activation after the deconvolution.\r\n",
    "\r\n",
    "        # Build the neural block\r\n",
    "        if not final_layer:\r\n",
    "            return nn.Sequential(\r\n",
    "                #### START CODE HERE ####\r\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size=kernel_size, stride=stride),\r\n",
    "                nn.BatchNorm2d(output_channels),\r\n",
    "                nn.ReLU(inplace=True)\r\n",
    "                #### END CODE HERE ####\r\n",
    "            )\r\n",
    "        else: # Final Layer\r\n",
    "            return nn.Sequential(\r\n",
    "                #### START CODE HERE ####\r\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\r\n",
    "                nn.Tanh()\r\n",
    "                #### END CODE HERE ####\r\n",
    "            )\r\n",
    "\r\n",
    "    def unsqueeze_noise(self, noise):\r\n",
    "        '''\r\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor, \r\n",
    "        returns a copy of that noise with width and height = 1 and channels = z_dim.\r\n",
    "        Parameters:\r\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\r\n",
    "        '''\r\n",
    "        return noise.view(len(noise), self.z_dim, 1, 1)\r\n",
    "\r\n",
    "    def forward(self, noise):\r\n",
    "        '''\r\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor, \r\n",
    "        returns generated images.\r\n",
    "        Parameters:\r\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\r\n",
    "        '''\r\n",
    "        x = self.unsqueeze_noise(noise)\r\n",
    "        return self.gen(x)\r\n",
    "\r\n",
    "def get_noise(n_samples, z_dim, device='cpu'):\r\n",
    "    '''\r\n",
    "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim)\r\n",
    "    creates a tensor of that shape filled with random numbers from the normal distribution.\r\n",
    "    Parameters:\r\n",
    "        n_samples: the number of samples to generate, a scalar\r\n",
    "        z_dim: the dimension of the noise vector, a scalar\r\n",
    "        device: the device type\r\n",
    "    '''\r\n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discriminator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\r\n",
    "# GRADED FUNCTION: Discriminator\r\n",
    "class Discriminator(nn.Module):\r\n",
    "    '''\r\n",
    "    Discriminator Class\r\n",
    "    Values:\r\n",
    "        im_chan: the number of channels of the output image, a scalar\r\n",
    "              (MNIST is black-and-white, so 1 channel is your default)\r\n",
    "    hidden_dim: the inner dimension, a scalar\r\n",
    "    '''\r\n",
    "    def __init__(self, im_chan=1, hidden_dim=16):\r\n",
    "        super(Discriminator, self).__init__()\r\n",
    "        self.disc = nn.Sequential(\r\n",
    "            self.make_disc_block(im_chan, hidden_dim),\r\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2),\r\n",
    "            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\r\n",
    "        )\r\n",
    "\r\n",
    "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\r\n",
    "        '''\r\n",
    "        Function to return a sequence of operations corresponding to a discriminator block of DCGAN, \r\n",
    "        corresponding to a convolution, a batchnorm (except for in the last layer), and an activation.\r\n",
    "        Parameters:\r\n",
    "            input_channels: how many channels the input feature representation has\r\n",
    "            output_channels: how many channels the output feature representation should have\r\n",
    "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\r\n",
    "            stride: the stride of the convolution\r\n",
    "            final_layer: a boolean, true if it is the final layer and false otherwise \r\n",
    "                      (affects activation and batchnorm)\r\n",
    "        '''\r\n",
    "        #     Steps:\r\n",
    "        #       1) Add a convolutional layer using the given parameters.\r\n",
    "        #       2) Do a batchnorm, except for the last layer.\r\n",
    "        #       3) Follow each batchnorm with a LeakyReLU activation with slope 0.2.\r\n",
    "        \r\n",
    "        # Build the neural block\r\n",
    "        if not final_layer:\r\n",
    "            return nn.Sequential(\r\n",
    "                #### START CODE HERE #### #\r\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\r\n",
    "                nn.BatchNorm2d(output_channels),\r\n",
    "                nn.LeakyReLU(0.2, inplace=True)\r\n",
    "                #### END CODE HERE ####\r\n",
    "            )\r\n",
    "        else: # Final Layer\r\n",
    "            return nn.Sequential(\r\n",
    "                #### START CODE HERE #### #\r\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride)\r\n",
    "                #### END CODE HERE ####\r\n",
    "            )\r\n",
    "\r\n",
    "    def forward(self, image):\r\n",
    "        '''\r\n",
    "        Function for completing a forward pass of the discriminator: Given an image tensor, \r\n",
    "        returns a 1-dimension tensor representing fake/real.\r\n",
    "        Parameters:\r\n",
    "            image: a flattened image tensor with dimension (im_dim)\r\n",
    "        '''\r\n",
    "        disc_pred = self.disc(image)\r\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\r\n",
    "z_dim = 64\r\n",
    "display_step = 500\r\n",
    "batch_size = 128\r\n",
    "# A learning rate of 0.0002 works well on DCGAN\r\n",
    "lr = 0.0002\r\n",
    "beta_1 = 0.5 \r\n",
    "beta_2 = 0.999\r\n",
    "device = 'cuda'\r\n",
    "\r\n",
    "# You can tranform the image values to be between -1 and 1 (the range of the tanh activation)\r\n",
    "transform = transforms.Compose([ transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,)),])\r\n",
    "\r\n",
    "dataloader = DataLoader( MNIST('.', download=False, transform=transform),  batch_size=batch_size,   shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gen = Generator(z_dim).to(device)\r\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\r\n",
    "disc = Discriminator().to(device) \r\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\r\n",
    "\r\n",
    "# You initialize the weights to the normal distribution\r\n",
    "# with mean 0 and standard deviation 0.02\r\n",
    "def weights_init(m):\r\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\r\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\r\n",
    "    if isinstance(m, nn.BatchNorm2d):\r\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\r\n",
    "        torch.nn.init.constant_(m.bias, 0)\r\n",
    "gen = gen.apply(weights_init)\r\n",
    "disc = disc.apply(weights_init)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_epochs = 100\r\n",
    "cur_step = 0\r\n",
    "mean_generator_loss = 0\r\n",
    "mean_discriminator_loss = 0\r\n",
    "for epoch in range(n_epochs):\r\n",
    "    # Dataloader returns the batches\r\n",
    "    for real, _ in tqdm(dataloader):\r\n",
    "        cur_batch_size = len(real)\r\n",
    "        real = real.to(device)\r\n",
    "\r\n",
    "        ## Update discriminator ##\r\n",
    "        disc_opt.zero_grad()\r\n",
    "        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\r\n",
    "        fake = gen(fake_noise)\r\n",
    "        disc_fake_pred = disc(fake.detach())\r\n",
    "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\r\n",
    "        disc_real_pred = disc(real)\r\n",
    "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\r\n",
    "        disc_loss = (disc_fake_loss + disc_real_loss) / 2\r\n",
    "\r\n",
    "        # Keep track of the average discriminator loss\r\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\r\n",
    "        # Update gradients\r\n",
    "        disc_loss.backward(retain_graph=True)\r\n",
    "        # Update optimizer\r\n",
    "        disc_opt.step()\r\n",
    "\r\n",
    "        ## Update generator ##\r\n",
    "        gen_opt.zero_grad()\r\n",
    "        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\r\n",
    "        fake_2 = gen(fake_noise_2)\r\n",
    "        disc_fake_pred = disc(fake_2)\r\n",
    "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\r\n",
    "        gen_loss.backward()\r\n",
    "        gen_opt.step()\r\n",
    "\r\n",
    "        # Keep track of the average generator loss\r\n",
    "        mean_generator_loss += gen_loss.item() / display_step\r\n",
    "\r\n",
    "    ## Visualization code ##\r\n",
    "    if (cur_step+1) % 5 == 0 and cur_step > 0:\r\n",
    "        print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\r\n",
    "        show_tensor_images(fake)\r\n",
    "        show_tensor_images(real)\r\n",
    "        mean_generator_loss = 0\r\n",
    "        mean_discriminator_loss = 0\r\n",
    "    cur_step += 1\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "81a32e34d9b6c3d3c08eec8886cc1ef58e5830ea13071be471581d66bf884ac5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}