{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "from tqdm.auto import tqdm\r\n",
    "from torchvision import transforms\r\n",
    "from torchvision.datasets import MNIST # Training dataset\r\n",
    "from torchvision.utils import make_grid\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!\r\n",
    "\r\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\r\n",
    "    '''\r\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\r\n",
    "    size per image, plots and prints the images in a uniform grid.\r\n",
    "    '''\r\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\r\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\r\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "aa= torch.arange(1,3)\r\n",
    "torch.dot (aa, torch.arange(3,5))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "in_height, in_width = data.shape[-2:]\r\n",
    "device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)\r\n",
    "boxes_per_pixel = (num_sizes + num_ratios - 1)\r\n",
    "size_tensor = torch.tensor(sizes, device=device)\r\n",
    "ratio_tensor = torch.tensor(ratios, device=device)\r\n",
    "\r\n",
    "# 为了将锚点移动到像素的中心，需要设置偏移量。\r\n",
    "# 因为一个像素的的高为1且宽为1，我们选择偏移我们的中心0.5\r\n",
    "offset_h, offset_w = 0.5, 0.5\r\n",
    "steps_h = 1.0 / in_height  # Scaled steps in y axis\r\n",
    "steps_w = 1.0 / in_width  # Scaled steps in x axis\r\n",
    "\r\n",
    "# 生成锚框的所有中心点\r\n",
    "center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h\r\n",
    "center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w\r\n",
    "shift_y, shift_x = torch.meshgrid(center_h, center_w)\r\n",
    "shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)\r\n",
    "\r\n",
    "# 生成“boxes_per_pixel”个高和宽，\r\n",
    "# 之后用于创建锚框的四角坐标 (xmin, xmax, ymin, ymax)\r\n",
    "w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),\r\n",
    "                sizes[0] * torch.sqrt(ratio_tensor[1:])))\\\r\n",
    "                * in_height / in_width  # Handle rectangular inputs\r\n",
    "h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),\r\n",
    "                sizes[0] / torch.sqrt(ratio_tensor[1:])))\r\n",
    "# 除以2来获得半高和半宽\r\n",
    "anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(\r\n",
    "                                    in_height * in_width, 1) / 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-29-d6aa6a58625c>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  size_tensor = torch.tensor(sizes, device=device)\n",
      "<ipython-input-29-d6aa6a58625c>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ratio_tensor = torch.tensor(ratios, device=device)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "anchor_manipulations[:10,:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.1000, -0.2000,  0.1000,  0.2000],\n",
       "        [-0.1500, -0.3000,  0.1500,  0.3000],\n",
       "        [-0.2000, -0.4000,  0.2000,  0.4000],\n",
       "        [-0.0775, -0.2582,  0.0775,  0.2582],\n",
       "        [-0.1183, -0.1690,  0.1183,  0.1690],\n",
       "        [-0.1000, -0.2000,  0.1000,  0.2000],\n",
       "        [-0.1500, -0.3000,  0.1500,  0.3000],\n",
       "        [-0.2000, -0.4000,  0.2000,  0.4000],\n",
       "        [-0.0775, -0.2582,  0.0775,  0.2582],\n",
       "        [-0.1183, -0.1690,  0.1183,  0.1690]])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "anchor_manipulations.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([100000, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "a = torch.tensor([1,2])\r\n",
    "a.repeat(2,3,4)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2]],\n",
       "\n",
       "        [[1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2]]])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "shift_x=torch.tensor([1,1,1,2,2,2,3,3,3])\r\n",
    "shift_y=torch.tensor([1,2,3,1,2,3,1,2,3])\r\n",
    "torch.stack([shift_x, shift_y],dim=1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 2, 1, 2],\n",
       "        [1, 3, 1, 3],\n",
       "        [2, 1, 2, 1],\n",
       "        [2, 2, 2, 2],\n",
       "        [2, 3, 2, 3],\n",
       "        [3, 1, 3, 1],\n",
       "        [3, 2, 3, 2],\n",
       "        [3, 3, 3, 3]])"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "81a32e34d9b6c3d3c08eec8886cc1ef58e5830ea13071be471581d66bf884ac5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}