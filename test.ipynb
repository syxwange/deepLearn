{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from pathlib import Path\r\n",
    "import torch\r\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2021-08-20(02.08)'"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.makedirs(\"images\", exist_ok=True)\r\n",
    "\r\n",
    "parser = argparse.ArgumentParser()\r\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=100, help=\"number of epochs of training\")\r\n",
    "parser.add_argument(\"--batch_size\", type=int, default=128, help=\"size of the batches\")\r\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\r\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\r\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\r\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\r\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\r\n",
    "parser.add_argument(\"--img_size\", type=int, default=28, help=\"size of each image dimension\")\r\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\r\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval betwen image samples\")\r\n",
    "opt = parser.parse_args()\r\n",
    "print(opt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "feature_map = torch.ones((1))                                                    # 1D\r\n",
    "feature_maps = torch.stack([feature_map*(i+1) for i in range(5)], dim=0) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "feature_maps_bs = torch.Tensor([[[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]],[[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]]])  \r\n",
    "feature_maps_bs = feature_maps_bs.unsqueeze(1)\r\n",
    "print(feature_maps_bs[0])\r\n",
    "\r\n",
    "bn = nn.BatchNorm2d(num_features=1, momentum=0.3)\r\n",
    "bn(feature_maps_bs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[1., 2., 3., 4., 5.],\n",
      "         [1., 2., 3., 4., 5.],\n",
      "         [1., 2., 3., 4., 5.]]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
       "          [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
       "          [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142]]],\n",
       "\n",
       "\n",
       "        [[[-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
       "          [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
       "          [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142]]]],\n",
       "       grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "print(bn.running_mean) \r\n",
    "bn.running_var"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.9000])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.3207])"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "os.makedirs(\"images\", exist_ok=True)\r\n",
    "parser = argparse.ArgumentParser()\r\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=100, help=\"number of epochs of training\")\r\n",
    "#parser.add_argument(\"--batch_size\", type=int, default=128, help=\"size of the batches\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--n_epochs'], dest='n_epochs', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, help='number of epochs of training', metavar=None)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "    batch_size = 3\r\n",
    "    num_features = 3\r\n",
    "    momentum = 0.3\r\n",
    "\r\n",
    "    features_shape = (2, 2)\r\n",
    "\r\n",
    "    feature_map = torch.ones(features_shape)                                                    # 2D\r\n",
    "    feature_maps = torch.stack([feature_map*(i+1) for i in range(num_features)], dim=0)         # 3D\r\n",
    "    feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)             # 4D\r\n",
    "\r\n",
    "    #print(feature_maps_bs)\r\n",
    "    print(feature_maps_bs.shape)\r\n",
    "    # print(\"input data:\\n{} shape is {}\".format(feature_maps_bs, feature_maps_bs.shape))\r\n",
    "\r\n",
    "    bn = nn.BatchNorm2d(num_features=num_features, momentum=momentum)\r\n",
    "\r\n",
    "    running_mean, running_var = 0, 1\r\n",
    "\r\n",
    "    for i in range(2):\r\n",
    "        outputs = bn(feature_maps_bs)\r\n",
    "        print('-'*19)\r\n",
    "        print(outputs.shape)\r\n",
    "        print(\"\\niter:{}, running_mean: {}\".format(i, bn.running_mean))\r\n",
    "        print(\"iter:{}, running_var: {}\".format(i, bn.running_var))\r\n",
    "\r\n",
    "        print(\"iter:{}, weight: {}\".format(i, bn.weight.data.numpy()))\r\n",
    "        print(\"iter:{}, bias: {}\".format(i, bn.bias.data.numpy()))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_13688/3710638433.py, line 21)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\syxwa\\AppData\\Local\\Temp/ipykernel_13688/3710638433.py\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    print(18*-)\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "10225e230a0ef510396827da287f7cf92eba04588ef8397eb0b6ba209c02b811"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}